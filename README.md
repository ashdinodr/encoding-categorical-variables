# Practical methods for encoding categorical features
The encoding of categorical (discrete) features as numerical values is a typical first-step toward preparing input data for machine learning. Ordinal (aka integer) encoding is commonly utilized to convert ordinal (ordered) categorical features to numerical values. There are many different ways of encoding nominal (arbitrarily ordered) categorical features to values that can be used with machine learning algorithms. Let's explore a few of the simple and common methods including one-hot (aka dummy) encoding, frequency encoding, target (aka mean) encoding, binary encoding, and hashing encoding techniques.

The project includes the integration of data preprocessing pipeplines into a end-to-end machine learning pipeline, using ColumnTransformer and Pipeline in scikit-learn.
